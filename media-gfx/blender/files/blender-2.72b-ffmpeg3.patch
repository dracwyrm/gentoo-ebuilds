diff -Naur blender-2.72b.orig/intern/audaspace/ffmpeg/AUD_FFMPEGReader.cpp blender-2.72b/intern/audaspace/ffmpeg/AUD_FFMPEGReader.cpp
--- blender-2.72b.orig/intern/audaspace/ffmpeg/AUD_FFMPEGReader.cpp	2017-06-25 17:36:31.465052736 +0200
+++ blender-2.72b/intern/audaspace/ffmpeg/AUD_FFMPEGReader.cpp	2017-06-25 17:37:23.433053898 +0200
@@ -58,9 +58,9 @@
 		got_frame = 0;
 
 		if(!frame)
-			frame = avcodec_alloc_frame();
+			frame = av_frame_alloc();	
 		else
-			avcodec_get_frame_defaults(frame);
+			av_frame_unref(frame);	
 
 		read_length = avcodec_decode_audio4(m_codecCtx, frame, &got_frame, &packet);
 		if(read_length < 0)
diff -Naur blender-2.72b.orig/intern/audaspace/ffmpeg/AUD_FFMPEGWriter.cpp blender-2.72b/intern/audaspace/ffmpeg/AUD_FFMPEGWriter.cpp
--- blender-2.72b.orig/intern/audaspace/ffmpeg/AUD_FFMPEGWriter.cpp	2017-06-25 17:36:31.465052736 +0200
+++ blender-2.72b/intern/audaspace/ffmpeg/AUD_FFMPEGWriter.cpp	2017-06-25 17:37:23.433053898 +0200
@@ -202,7 +202,7 @@
 			m_frame = av_frame_alloc();
 			if (!m_frame)
 				AUD_THROW(AUD_ERROR_FFMPEG, codec_error);
-			avcodec_get_frame_defaults(m_frame);
+			av_frame_unref(m_frame);	
 			m_frame->linesize[0]    = m_input_size * samplesize;
 			m_frame->format         = m_codecCtx->sample_fmt;
 			m_frame->nb_samples     = m_input_size;
@@ -224,7 +224,9 @@
 				if(avio_open(&m_formatCtx->pb, filename.c_str(), AVIO_FLAG_WRITE))
 					AUD_THROW(AUD_ERROR_FILE, file_error);
 
-				avformat_write_header(m_formatCtx, NULL);
+				if(avformat_write_header(m_formatCtx, NULL) < 0) {
+                    			throw;
+                }	
 			}
 			catch(AUD_Exception&)
 			{
diff -Naur blender-2.72b.orig/intern/ffmpeg/ffmpeg_compat.h blender-2.72b/intern/ffmpeg/ffmpeg_compat.h
--- blender-2.72b.orig/intern/ffmpeg/ffmpeg_compat.h	2017-06-25 17:36:31.475052736 +0200
+++ blender-2.72b/intern/ffmpeg/ffmpeg_compat.h	2017-06-25 17:38:19.723055158 +0200
@@ -446,4 +446,230 @@
 #  define FFMPEG_HAVE_DEPRECATED_FLAGS2
 #endif
 
+/* Since FFmpeg-1.1 this constant have AV_ prefix. */
+#if LIBAVUTIL_VERSION_INT < AV_VERSION_INT(52, 13, 100)
+#  define AV_PIX_FMT_BGR32 PIX_FMT_BGR32
+#  define AV_PIX_FMT_YUV422P PIX_FMT_YUV422P
+#  define AV_PIX_FMT_BGRA PIX_FMT_BGRA
+#  define AV_PIX_FMT_ARGB PIX_FMT_ARGB
+#  define AV_PIX_FMT_RGBA PIX_FMT_RGBA
+#endif
+
+/* New API from FFmpeg-2.0 which soon became recommended one. */
+#if LIBAVUTIL_VERSION_INT < AV_VERSION_INT(52, 38, 100)
+#  define av_frame_alloc avcodec_alloc_frame
+#  define av_frame_free avcodec_free_frame
+#  define av_frame_unref avcodec_get_frame_defaults
+#endif
+
+#if LIBAVCODEC_VERSION_INT >= AV_VERSION_INT(57, 24, 102)
+
+/* NOTE: The code in this block are from FFmpeg 2.6.4, which is licensed by LGPL. */
+
+#define MAX_NEG_CROP 1024
+
+#define times4(x) x, x, x, x
+#define times256(x) times4(times4(times4(times4(times4(x)))))
+
+static const uint8_t ff_compat_crop_tab[256 + 2 * MAX_NEG_CROP] = {
+times256(0x00),
+0x00,0x01,0x02,0x03,0x04,0x05,0x06,0x07,0x08,0x09,0x0A,0x0B,0x0C,0x0D,0x0E,0x0F,
+0x10,0x11,0x12,0x13,0x14,0x15,0x16,0x17,0x18,0x19,0x1A,0x1B,0x1C,0x1D,0x1E,0x1F,
+0x20,0x21,0x22,0x23,0x24,0x25,0x26,0x27,0x28,0x29,0x2A,0x2B,0x2C,0x2D,0x2E,0x2F,
+0x30,0x31,0x32,0x33,0x34,0x35,0x36,0x37,0x38,0x39,0x3A,0x3B,0x3C,0x3D,0x3E,0x3F,
+0x40,0x41,0x42,0x43,0x44,0x45,0x46,0x47,0x48,0x49,0x4A,0x4B,0x4C,0x4D,0x4E,0x4F,
+0x50,0x51,0x52,0x53,0x54,0x55,0x56,0x57,0x58,0x59,0x5A,0x5B,0x5C,0x5D,0x5E,0x5F,
+0x60,0x61,0x62,0x63,0x64,0x65,0x66,0x67,0x68,0x69,0x6A,0x6B,0x6C,0x6D,0x6E,0x6F,
+0x70,0x71,0x72,0x73,0x74,0x75,0x76,0x77,0x78,0x79,0x7A,0x7B,0x7C,0x7D,0x7E,0x7F,
+0x80,0x81,0x82,0x83,0x84,0x85,0x86,0x87,0x88,0x89,0x8A,0x8B,0x8C,0x8D,0x8E,0x8F,
+0x90,0x91,0x92,0x93,0x94,0x95,0x96,0x97,0x98,0x99,0x9A,0x9B,0x9C,0x9D,0x9E,0x9F,
+0xA0,0xA1,0xA2,0xA3,0xA4,0xA5,0xA6,0xA7,0xA8,0xA9,0xAA,0xAB,0xAC,0xAD,0xAE,0xAF,
+0xB0,0xB1,0xB2,0xB3,0xB4,0xB5,0xB6,0xB7,0xB8,0xB9,0xBA,0xBB,0xBC,0xBD,0xBE,0xBF,
+0xC0,0xC1,0xC2,0xC3,0xC4,0xC5,0xC6,0xC7,0xC8,0xC9,0xCA,0xCB,0xCC,0xCD,0xCE,0xCF,
+0xD0,0xD1,0xD2,0xD3,0xD4,0xD5,0xD6,0xD7,0xD8,0xD9,0xDA,0xDB,0xDC,0xDD,0xDE,0xDF,
+0xE0,0xE1,0xE2,0xE3,0xE4,0xE5,0xE6,0xE7,0xE8,0xE9,0xEA,0xEB,0xEC,0xED,0xEE,0xEF,
+0xF0,0xF1,0xF2,0xF3,0xF4,0xF5,0xF6,0xF7,0xF8,0xF9,0xFA,0xFB,0xFC,0xFD,0xFE,0xFF,
+times256(0xFF)
+};
+
+#undef times4
+#undef times256
+
+/* filter parameters: [-1 4 2 4 -1] // 8 */
+FFMPEG_INLINE
+void deinterlace_line(uint8_t *dst,
+                      const uint8_t *lum_m4, const uint8_t *lum_m3,
+                      const uint8_t *lum_m2, const uint8_t *lum_m1,
+                      const uint8_t *lum,
+                      int size)
+{
+    const uint8_t *cm = ff_compat_crop_tab + MAX_NEG_CROP;
+    int sum;
+
+    for(;size > 0;size--) {
+        sum = -lum_m4[0];
+        sum += lum_m3[0] << 2;
+        sum += lum_m2[0] << 1;
+        sum += lum_m1[0] << 2;
+        sum += -lum[0];
+        dst[0] = cm[(sum + 4) >> 3];
+        lum_m4++;
+        lum_m3++;
+        lum_m2++;
+        lum_m1++;
+        lum++;
+        dst++;
+    }
+}
+
+FFMPEG_INLINE
+void deinterlace_line_inplace(uint8_t *lum_m4, uint8_t *lum_m3,
+                              uint8_t *lum_m2, uint8_t *lum_m1,
+                              uint8_t *lum, int size)
+{
+    const uint8_t *cm = ff_compat_crop_tab + MAX_NEG_CROP;
+    int sum;
+
+    for(;size > 0;size--) {
+        sum = -lum_m4[0];
+        sum += lum_m3[0] << 2;
+        sum += lum_m2[0] << 1;
+        lum_m4[0]=lum_m2[0];
+        sum += lum_m1[0] << 2;
+        sum += -lum[0];
+        lum_m2[0] = cm[(sum + 4) >> 3];
+        lum_m4++;
+        lum_m3++;
+        lum_m2++;
+        lum_m1++;
+        lum++;
+    }
+}
+
+/* deinterlacing : 2 temporal taps, 3 spatial taps linear filter. The
+   top field is copied as is, but the bottom field is deinterlaced
+   against the top field. */
+FFMPEG_INLINE
+void deinterlace_bottom_field(uint8_t *dst, int dst_wrap,
+                              const uint8_t *src1, int src_wrap,
+                              int width, int height)
+{
+    const uint8_t *src_m2, *src_m1, *src_0, *src_p1, *src_p2;
+    int y;
+
+    src_m2 = src1;
+    src_m1 = src1;
+    src_0=&src_m1[src_wrap];
+    src_p1=&src_0[src_wrap];
+    src_p2=&src_p1[src_wrap];
+    for(y=0;y<(height-2);y+=2) {
+        memcpy(dst,src_m1,width);
+        dst += dst_wrap;
+        deinterlace_line(dst,src_m2,src_m1,src_0,src_p1,src_p2,width);
+        src_m2 = src_0;
+        src_m1 = src_p1;
+        src_0 = src_p2;
+        src_p1 += 2*src_wrap;
+        src_p2 += 2*src_wrap;
+        dst += dst_wrap;
+    }
+    memcpy(dst,src_m1,width);
+    dst += dst_wrap;
+    /* do last line */
+    deinterlace_line(dst,src_m2,src_m1,src_0,src_0,src_0,width);
+}
+
+FFMPEG_INLINE
+int deinterlace_bottom_field_inplace(uint8_t *src1, int src_wrap,
+                                     int width, int height)
+{
+    uint8_t *src_m1, *src_0, *src_p1, *src_p2;
+    int y;
+    uint8_t *buf = (uint8_t *)av_malloc(width);
+    if (!buf)
+        return AVERROR(ENOMEM);
+
+    src_m1 = src1;
+    memcpy(buf,src_m1,width);
+    src_0=&src_m1[src_wrap];
+    src_p1=&src_0[src_wrap];
+    src_p2=&src_p1[src_wrap];
+    for(y=0;y<(height-2);y+=2) {
+        deinterlace_line_inplace(buf,src_m1,src_0,src_p1,src_p2,width);
+        src_m1 = src_p1;
+        src_0 = src_p2;
+        src_p1 += 2*src_wrap;
+        src_p2 += 2*src_wrap;
+    }
+    /* do last line */
+    deinterlace_line_inplace(buf,src_m1,src_0,src_0,src_0,width);
+    av_free(buf);
+    return 0;
+}
+
+#ifdef __GNUC__
+#  pragma GCC diagnostic push
+#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+#endif
+
+FFMPEG_INLINE
+int avpicture_deinterlace(AVPicture *dst, const AVPicture *src,
+                          enum AVPixelFormat pix_fmt, int width, int height)
+{
+    int i, ret;
+
+    if (pix_fmt != AV_PIX_FMT_YUV420P &&
+        pix_fmt != AV_PIX_FMT_YUVJ420P &&
+        pix_fmt != AV_PIX_FMT_YUV422P &&
+        pix_fmt != AV_PIX_FMT_YUVJ422P &&
+        pix_fmt != AV_PIX_FMT_YUV444P &&
+        pix_fmt != AV_PIX_FMT_YUV411P &&
+        pix_fmt != AV_PIX_FMT_GRAY8)
+        return -1;
+    if ((width & 3) != 0 || (height & 3) != 0)
+        return -1;
+
+    for(i=0;i<3;i++) {
+        if (i == 1) {
+            switch(pix_fmt) {
+            case AV_PIX_FMT_YUVJ420P:
+            case AV_PIX_FMT_YUV420P:
+                width >>= 1;
+                height >>= 1;
+                break;
+            case AV_PIX_FMT_YUV422P:
+            case AV_PIX_FMT_YUVJ422P:
+                width >>= 1;
+                break;
+            case AV_PIX_FMT_YUV411P:
+                width >>= 2;
+                break;
+            default:
+                break;
+            }
+            if (pix_fmt == AV_PIX_FMT_GRAY8) {
+                break;
+            }
+        }
+        if (src == dst) {
+            ret = deinterlace_bottom_field_inplace(dst->data[i],
+                                                   dst->linesize[i],
+                                                   width, height);
+            if (ret < 0)
+                return ret;
+        } else {
+            deinterlace_bottom_field(dst->data[i],dst->linesize[i],
+                                     src->data[i], src->linesize[i],
+                                     width, height);
+        }
+    }
+    return 0;
+}
+
+#ifdef __GNUC__
+#  pragma GCC diagnostic pop
+#endif
+
+#endif
+
 #endif
diff -Naur blender-2.72b.orig/source/blender/blenkernel/intern/writeffmpeg.c blender-2.72b/source/blender/blenkernel/intern/writeffmpeg.c
--- blender-2.72b.orig/source/blender/blenkernel/intern/writeffmpeg.c	2017-06-25 17:36:31.559052738 +0200
+++ blender-2.72b/source/blender/blenkernel/intern/writeffmpeg.c	2017-06-25 17:37:23.435053899 +0200
@@ -134,8 +134,8 @@
 	audio_time += (double) audio_input_samples / (double) c->sample_rate;
 
 #ifdef FFMPEG_HAVE_ENCODE_AUDIO2
-	frame = avcodec_alloc_frame();
-	avcodec_get_frame_defaults(frame);
+	frame = av_frame_alloc();
+    	av_frame_unref(frame);
 	frame->pts = audio_time / av_q2d(c->time_base);
 	frame->nb_samples = audio_input_samples;
 	frame->format = c->sample_fmt;
@@ -168,7 +168,7 @@
 	}
 
 	if (!got_output) {
-		avcodec_free_frame(&frame);
+		av_frame_free(&frame);	
 		return 0;
 	}
 #else
@@ -198,7 +198,7 @@
 		if (av_interleaved_write_frame(outfile, &pkt) != 0) {
 			fprintf(stderr, "Error writing audio packet!\n");
 			if (frame)
-				avcodec_free_frame(&frame);
+				av_frame_free(&frame);
 			return -1;
 		}
 
@@ -206,7 +206,7 @@
 	}
 
 	if (frame)
-		avcodec_free_frame(&frame);
+		av_frame_free(&frame);
 
 	return 0;
 }
@@ -220,7 +220,7 @@
 	int size;
 	
 	/* allocate space for the struct */
-	f = avcodec_alloc_frame();
+	f = av_frame_alloc();
 	if (!f) return NULL;
 	size = avpicture_get_size(pix_fmt, width, height);
 	/* allocate the actual picture buffer */
@@ -359,8 +359,8 @@
 	int height = c->height;
 	AVFrame *rgb_frame;
 
-	if (c->pix_fmt != PIX_FMT_BGR32) {
-		rgb_frame = alloc_picture(PIX_FMT_BGR32, width, height);
+    	if (c->pix_fmt != AV_PIX_FMT_BGR32) {
+        	rgb_frame = alloc_picture(AV_PIX_FMT_BGR32, width, height);
 		if (!rgb_frame) {
 			BKE_report(reports, RPT_ERROR, "Could not allocate temporary frame");
 			return NULL;
@@ -410,14 +410,14 @@
 		}
 	}
 
-	if (c->pix_fmt != PIX_FMT_BGR32) {
+	if (c->pix_fmt != AV_PIX_FMT_BGR32) {
 		sws_scale(img_convert_ctx, (const uint8_t *const *) rgb_frame->data,
 		          rgb_frame->linesize, 0, c->height,
 		          current_frame->data, current_frame->linesize);
 		delete_picture(rgb_frame);
 	}
 
-	current_frame->format = PIX_FMT_BGR32;
+	current_frame->format = AV_PIX_FMT_BGR32;
 	current_frame->width = width;
 	current_frame->height = height;
 
@@ -585,12 +585,12 @@
 	}
 	else {
 		/* makes HuffYUV happy ... */
-		c->pix_fmt = PIX_FMT_YUV422P;
+		c->pix_fmt = AV_PIX_FMT_YUV422P;
 	}
 
 	if (ffmpeg_type == FFMPEG_XVID) {
 		/* arghhhh ... */
-		c->pix_fmt = PIX_FMT_YUV420P;
+		c->pix_fmt = AV_PIX_FMT_YUV420P;
 		c->codec_tag = (('D' << 24) + ('I' << 16) + ('V' << 8) + 'X');
 	}
 
@@ -603,22 +603,22 @@
 	/* Keep lossless encodes in the RGB domain. */
 	if (codec_id == AV_CODEC_ID_HUFFYUV) {
 		/* HUFFYUV was PIX_FMT_YUV422P before */
-		c->pix_fmt = PIX_FMT_RGB32;
+		c->pix_fmt = AV_PIX_FMT_RGB32;
 	}
 
 	if (codec_id == AV_CODEC_ID_FFV1) {
-		c->pix_fmt = PIX_FMT_RGB32;
+		c->pix_fmt = AV_PIX_FMT_RGB32;
 	}
 
 	if (codec_id == AV_CODEC_ID_QTRLE) {
 		if (rd->im_format.planes == R_IMF_PLANES_RGBA) {
-			c->pix_fmt = PIX_FMT_ARGB;
+			c->pix_fmt = AV_PIX_FMT_ARGB;
 		}
 	}
 
 	if (codec_id == AV_CODEC_ID_PNG) {
 		if (rd->im_format.planes == R_IMF_PLANES_RGBA) {
-			c->pix_fmt = PIX_FMT_RGBA;
+			c->pix_fmt = AV_PIX_FMT_RGBA;
 		}
 	}
 
@@ -656,7 +656,7 @@
 
 	current_frame = alloc_picture(c->pix_fmt, c->width, c->height);
 
-	img_convert_ctx = sws_getContext(c->width, c->height, PIX_FMT_BGR32, c->width, c->height, c->pix_fmt, SWS_BICUBIC,
+	img_convert_ctx = sws_getContext(c->width, c->height, AV_PIX_FMT_BGR32, c->width, c->height, c->pix_fmt, SWS_BICUBIC,
 	                                 NULL, NULL, NULL);
 	return st;
 }
diff -Naur blender-2.72b.orig/source/blender/imbuf/intern/anim_movie.c blender-2.72b/source/blender/imbuf/intern/anim_movie.c
--- blender-2.72b.orig/source/blender/imbuf/intern/anim_movie.c	2017-06-25 17:36:31.583052739 +0200
+++ blender-2.72b/source/blender/imbuf/intern/anim_movie.c	2017-06-25 17:37:23.436053899 +0200
@@ -565,12 +565,12 @@
 	anim->next_pts = -1;
 	anim->next_packet.stream_index = -1;
 
-	anim->pFrame = avcodec_alloc_frame();
+	anim->pFrame = av_frame_alloc();
 	anim->pFrameComplete = false;
-	anim->pFrameDeinterlaced = avcodec_alloc_frame();
-	anim->pFrameRGB = avcodec_alloc_frame();
+	anim->pFrameDeinterlaced = av_frame_alloc();
+	anim->pFrameRGB = av_frame_alloc();
 
-	if (avpicture_get_size(PIX_FMT_RGBA, anim->x, anim->y) !=
+	if (avpicture_get_size(AV_PIX_FMT_RGBA, anim->x, anim->y) !=
 	    anim->x * anim->y * 4)
 	{
 		fprintf(stderr,
@@ -609,7 +609,7 @@
 	        anim->pCodecCtx->pix_fmt,
 	        anim->x,
 	        anim->y,
-	        PIX_FMT_RGBA,
+	        AV_PIX_FMT_RGBA,
 	        SWS_FAST_BILINEAR | SWS_PRINT_INFO | SWS_FULL_CHR_H_INT,
 	        NULL, NULL, NULL);
 		
@@ -698,7 +698,7 @@
 	
 	avpicture_fill((AVPicture *) anim->pFrameRGB,
 	               (unsigned char *) ibuf->rect,
-	               PIX_FMT_RGBA, anim->x, anim->y);
+	               AV_PIX_FMT_RGBA, anim->x, anim->y);
 
 	if (ENDIAN_ORDER == B_ENDIAN) {
 		int *dstStride   = anim->pFrameRGB->linesize;
diff -Naur blender-2.72b.orig/source/blender/imbuf/intern/indexer.c blender-2.72b/source/blender/imbuf/intern/indexer.c
--- blender-2.72b.orig/source/blender/imbuf/intern/indexer.c	2017-06-25 17:36:31.584052739 +0200
+++ blender-2.72b/source/blender/imbuf/intern/indexer.c	2017-06-25 17:37:23.436053899 +0200
@@ -515,7 +515,7 @@
 		rv->c->pix_fmt = rv->codec->pix_fmts[0];
 	}
 	else {
-		rv->c->pix_fmt = PIX_FMT_YUVJ420P;
+		rv->c->pix_fmt = AV_PIX_FMT_YUVJ420P;
 	}
 
 	rv->c->sample_aspect_ratio =
@@ -550,7 +550,7 @@
 	if (st->codec->width != width || st->codec->height != height ||
 	    st->codec->pix_fmt != rv->c->pix_fmt)
 	{
-		rv->frame = avcodec_alloc_frame();
+		rv->frame = av_frame_alloc();
 		avpicture_fill((AVPicture *) rv->frame,
 		               MEM_mallocN(avpicture_get_size(
 		                               rv->c->pix_fmt,
@@ -901,7 +901,7 @@
 
 	memset(&next_packet, 0, sizeof(AVPacket));
 
-	in_frame = avcodec_alloc_frame();
+	in_frame = av_frame_alloc();
 
 	stream_size = avio_size(context->iFormatCtx->pb);
 
diff -Naur blender-2.72b.orig/source/gameengine/VideoTexture/VideoFFmpeg.cpp blender-2.72b/source/gameengine/VideoTexture/VideoFFmpeg.cpp
--- blender-2.72b.orig/source/gameengine/VideoTexture/VideoFFmpeg.cpp	2017-06-25 17:36:31.598052739 +0200
+++ blender-2.72b/source/gameengine/VideoTexture/VideoFFmpeg.cpp	2017-06-25 17:37:23.436053899 +0200
@@ -133,23 +133,23 @@
 AVFrame	*VideoFFmpeg::allocFrameRGB()
 {
 	AVFrame *frame;
-	frame = avcodec_alloc_frame();
+	frame = av_frame_alloc();
 	if (m_format == RGBA32)
 	{
 		avpicture_fill((AVPicture*)frame, 
 			(uint8_t*)MEM_callocN(avpicture_get_size(
-				PIX_FMT_RGBA,
+				AV_PIX_FMT_RGBA,
 				m_codecCtx->width, m_codecCtx->height),
 				"ffmpeg rgba"),
-			PIX_FMT_RGBA, m_codecCtx->width, m_codecCtx->height);
+			AV_PIX_FMT_RGBA, m_codecCtx->width, m_codecCtx->height);
 	} else 
 	{
 		avpicture_fill((AVPicture*)frame, 
 			(uint8_t*)MEM_callocN(avpicture_get_size(
-				PIX_FMT_RGB24,
+				AV_PIX_FMT_RGB24,
 				m_codecCtx->width, m_codecCtx->height),
 				"ffmpeg rgb"),
-			PIX_FMT_RGB24, m_codecCtx->width, m_codecCtx->height);
+			AV_PIX_FMT_RGB24, m_codecCtx->width, m_codecCtx->height);
 	}
 	return frame;
 }
@@ -229,8 +229,8 @@
 	m_codecCtx = codecCtx;
 	m_formatCtx = formatCtx;
 	m_videoStream = videoStream;
-	m_frame = avcodec_alloc_frame();
-	m_frameDeinterlaced = avcodec_alloc_frame();
+	m_frame = av_frame_alloc();
+	m_frameDeinterlaced = av_frame_alloc();
 
 	// allocate buffer if deinterlacing is required
 	avpicture_fill((AVPicture*)m_frameDeinterlaced, 
@@ -241,10 +241,10 @@
 		m_codecCtx->pix_fmt, m_codecCtx->width, m_codecCtx->height);
 
 	// check if the pixel format supports Alpha
-	if (m_codecCtx->pix_fmt == PIX_FMT_RGB32 ||
-		m_codecCtx->pix_fmt == PIX_FMT_BGR32 ||
-		m_codecCtx->pix_fmt == PIX_FMT_RGB32_1 ||
-		m_codecCtx->pix_fmt == PIX_FMT_BGR32_1) 
+	if (m_codecCtx->pix_fmt == AV_PIX_FMT_RGB32 ||
+		m_codecCtx->pix_fmt == AV_PIX_FMT_BGR32 ||
+		m_codecCtx->pix_fmt == AV_PIX_FMT_RGB32_1 ||
+		m_codecCtx->pix_fmt == AV_PIX_FMT_BGR32_1) 
 	{
 		// allocate buffer to store final decoded frame
 		m_format = RGBA32;
@@ -255,7 +255,7 @@
 			m_codecCtx->pix_fmt,
 			m_codecCtx->width,
 			m_codecCtx->height,
-			PIX_FMT_RGBA,
+			AV_PIX_FMT_RGBA,
 			SWS_FAST_BILINEAR,
 			NULL, NULL, NULL);
 	} else
@@ -269,7 +269,7 @@
 			m_codecCtx->pix_fmt,
 			m_codecCtx->width,
 			m_codecCtx->height,
-			PIX_FMT_RGB24,
+			AV_PIX_FMT_RGB24,
 			SWS_FAST_BILINEAR,
 			NULL, NULL, NULL);
 	}
